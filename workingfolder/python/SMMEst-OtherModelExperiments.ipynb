{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theories of Expectation Formation with Inflation Expectation\n",
    "\n",
    "- The code is organized in following ways\n",
    "\n",
    "  1. Each pair of a theory of expectation formation (re, se, ni, de, denim etc) and an assumed process of inflation process (ar1 or sv)  are encapsulated in a specific python class. \n",
    "    - the class initializes corresponding parameters of the inflation process and expectation formation \n",
    "    - and embodies a specific function that generates all the simulated moments of both inflation and expectations \n",
    "    \n",
    "  2. A generally written objective function that computes the distances in moments as a function of parameters specific to the chosen model, moments, and the data. \n",
    "  3.  The general function is to be used to compute the specific objective function that takes parameter as the only input for the minimizer to work\n",
    "  4.  Then a general function that does an optimization algorithm takes the specific objective function and estimates the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from numba import njit, float64, int64\n",
    "from numba.experimental import jitclass\n",
    "import pandas as pd\n",
    "lw = 4\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SMMEst import RationalExpectationAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     2,
     23,
     47,
     72,
     120
    ]
   },
   "outputs": [],
   "source": [
    "## auxiliary functions \n",
    "@njit\n",
    "def hstepvar(h,\n",
    "             ρ,\n",
    "             σ):\n",
    "    '''\n",
    "    inputs\n",
    "    ------\n",
    "    h: forecast horizon\n",
    "    ρ: ar(1) persistence\n",
    "    σ: ar(1) volatility (standard deviation)\n",
    "    \n",
    "    outputs\n",
    "    -------\n",
    "    scalar: h-step-forward variance \n",
    "    '''\n",
    "    ## h-step ahead variance for an ar(1)\n",
    "    var = 0\n",
    "    for i in range(h):\n",
    "        var += ρ**(2*i)*σ**2 \n",
    "    return var \n",
    "\n",
    "@njit\n",
    "def hstepvarSV(h,\n",
    "               σs_now,\n",
    "               γ):\n",
    "    '''\n",
    "    inputs\n",
    "    ------\n",
    "    h: forecast horizon\n",
    "    σs_now, 2 x 1 vector [sigma_eta, sigma_eps]\n",
    "    γ, volatility, scalar. \n",
    "    \n",
    "    outputs\n",
    "    -------\n",
    "    scalar: h-step-forward variance \n",
    "    '''\n",
    "    ratio = 0\n",
    "    for k in range(h):\n",
    "        ratio += np.exp(-0.5*(k+1)*γ)\n",
    "    var_eta = σs_now[0]**2*ratio\n",
    "    var_eps = σs_now[1]**2*np.exp(-0.5*h*γ)\n",
    "    var = var_eta + var_eps\n",
    "    return var\n",
    "\n",
    "### AR1 simulator \n",
    "@njit\n",
    "def SimAR1(ρ,\n",
    "           σ,\n",
    "           T):\n",
    "    '''\n",
    "    inputs\n",
    "    ------\n",
    "    T: nb of periods for the simulated history \n",
    "    ρ: ar(1) persistence\n",
    "    σ: ar(1) volatility (standard deviation)\n",
    "    \n",
    "    outputs\n",
    "    -------\n",
    "    xxx: T periods of history of AR(1) with the first 20 periods burned \n",
    "    '''\n",
    "        \n",
    "    t_burn = 20\n",
    "    xxx = np.zeros(T+1+t_burn)\n",
    "    shocks = np.random.randn(T+1+t_burn)*σ\n",
    "    xxx[0] = 0 \n",
    "    for i in range(T+t_burn):\n",
    "        xxx[i+1] = ρ*xxx[i] + shocks[i+1]\n",
    "    return xxx[1+t_burn:]\n",
    "\n",
    "### UC-SV simulator \n",
    "@njit\n",
    "def SimUCSV(γ,\n",
    "            nobs,\n",
    "            p0 = 0,\n",
    "            seed = False):\n",
    "    \"\"\"\n",
    "    input\n",
    "    ======\n",
    "    p: permanent \n",
    "    t: transitory \n",
    "    \n",
    "    output\n",
    "    ======\n",
    "    y: the draw of series\n",
    "    p: the permanent component\n",
    "    svols_p: permanent volatility \n",
    "    svols_t: transitory volatility \n",
    "    \"\"\"\n",
    "    if seed:\n",
    "        np.random.seed(12344)\n",
    "    else:\n",
    "        pass\n",
    "    svols_p_shock = np.random.randn(nobs+1)*γ\n",
    "    svols_t_shock = np.random.randn(nobs+1)*γ\n",
    "    \n",
    "    svols_p = np.zeros(nobs+1)\n",
    "    svols_p[0] = 0.001\n",
    "    svols_t = np.zeros(nobs+1)\n",
    "    svols_t[0] = 0.001\n",
    "    for i in range(nobs):\n",
    "        svols_p[i+1] = np.sqrt( np.exp(np.log(svols_p[i]**2) + svols_p_shock[i+1]) ) \n",
    "        svols_t[i+1] = np.sqrt( np.exp(np.log(svols_t[i]**2) + svols_t_shock[i+1]) ) \n",
    "    shocks_p = np.multiply(np.random.randn(nobs+1),svols_p)  \n",
    "    shocks_t = np.multiply(np.random.randn(nobs+1),svols_t)\n",
    "    \n",
    "    p = np.zeros(nobs+1)\n",
    "    t = np.zeros(nobs+1)\n",
    "    \n",
    "    ## initial level of eta, 0 by default\n",
    "    p[0] = p0\n",
    "    \n",
    "    for i in range(nobs):\n",
    "        p[i+1] = p[i] + shocks_p[i+1]\n",
    "        t[i+1] = shocks_t[i+1]\n",
    "        \n",
    "    y = p + t\n",
    "    return y, p, svols_p, svols_t\n",
    "\n",
    "@njit\n",
    "def d1tod2(x):\n",
    "    '''\n",
    "    inputs\n",
    "    ------\n",
    "    x: 1-dimension array \n",
    "    \n",
    "    outputs\n",
    "    -------\n",
    "    2-dimension array \n",
    "    '''\n",
    "    return x.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     1,
     37
    ]
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def ObjGen(model,\n",
    "           paras,\n",
    "           data_mom_dict,\n",
    "           moment_choice,\n",
    "           how = 'expectation',\n",
    "           n_exp_paras = 0):\n",
    "    '''\n",
    "    inputs\n",
    "    ------\n",
    "    model: a model class, i.e, sear representing sticky expectation and ar(1) \n",
    "    paras: an array vector of the parameters, which potentially includes both inflation process and expectation \n",
    "    data_mom_dic: a dictionary storing all data moments\n",
    "    moment_choice: a list of moments, i.e. ['FE','FEATV','Var']\n",
    "    how: string taking values of 'expectation','process','joint'\n",
    "    n_exp_paras: nb of parameters for expectation model \n",
    "    \n",
    "    outputs\n",
    "    -------\n",
    "    distance: the scalar of the moment distances to be minimized\n",
    "    '''\n",
    "    if how =='expectation':\n",
    "        model.exp_para = paras\n",
    "    elif how=='process':\n",
    "        model.process_para = paras\n",
    "    elif how=='joint':\n",
    "        model.exp_para = paras[0:n_exp_paras]\n",
    "        model.process_para = paras[n_exp_paras:]\n",
    "        \n",
    "    # simulated moments \n",
    "    model_mom_dict = model.SMM()\n",
    "    diff = np.array([model_mom_dict[mom] - data_mom_dict[mom] for mom in moment_choice]) \n",
    "    distance = np.linalg.norm(diff)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "@njit\n",
    "def ObjWeight(model,\n",
    "           paras,\n",
    "           data_mom_dict,\n",
    "           moment_choice,\n",
    "           weight,\n",
    "           how = 'expectation',\n",
    "           n_exp_paras = 0):\n",
    "    '''\n",
    "    - same as above ObjGen, except for with one additional argument weight for weighted distance \n",
    "    '''\n",
    "    \n",
    "    if how =='expectation':\n",
    "        model.exp_para = paras\n",
    "    elif how=='process':\n",
    "        model.process_para = paras\n",
    "    elif how=='joint':\n",
    "        model.exp_para = paras[0:n_exp_paras]\n",
    "        model.process_para = paras[n_exp_paras:]\n",
    "        \n",
    "    # simulated moments \n",
    "    model_mom_dict = model.SMM()\n",
    "    diff = np.array([model_mom_dict[mom] - data_mom_dict[mom] for mom in moment_choice])\n",
    "    distance = np.dot(np.dot(diff,weight),diff.T)  ## need to make sure it is right. \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "## parameter estimation non-jitted because jit does not support scipy.optimize\n",
    "def ParaEst(ObjSpec,\n",
    "            para_guess,\n",
    "            method = 'Nelder-Mead',\n",
    "            bounds = None,\n",
    "            options = {'disp': True}):\n",
    "    \"\"\"\n",
    "    an estimating function that minimizes OjbSpec function that gives parameter estimates\n",
    "    \"\"\"\n",
    "    results = minimize(ObjSpec,\n",
    "                         x0 = para_guess,\n",
    "                         method = method,\n",
    "                         bounds = bounds,\n",
    "                         options = options)\n",
    "    if results['success']==True:\n",
    "        parameter = results['x']\n",
    "    else:\n",
    "        parameter = np.array([])\n",
    "    \n",
    "    return parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Some jitted functions that are needed (https://github.com/numba/numba/issues/1269)\n",
    "\n",
    "@njit\n",
    "def np_apply_along_axis(func1d, axis, arr):\n",
    "    assert arr.ndim == 2\n",
    "    assert axis in [0, 1]\n",
    "    if axis == 0:\n",
    "        result = np.empty(arr.shape[1])\n",
    "        for i in range(len(result)):\n",
    "            result[i] = func1d(arr[:, i])\n",
    "    else:\n",
    "        result = np.empty(arr.shape[0])\n",
    "        for i in range(len(result)):\n",
    "            result[i] = func1d(arr[i, :])\n",
    "    return result\n",
    "\n",
    "@njit\n",
    "def np_mean(array, axis):\n",
    "    return np_apply_along_axis(np.mean, axis, array)\n",
    "\n",
    "@njit\n",
    "def np_std(array, axis):\n",
    "    return np_apply_along_axis(np.std, axis, array)\n",
    "\n",
    "@njit\n",
    "def np_var(array, axis):\n",
    "    return np_apply_along_axis(np.var, axis, array)\n",
    "\n",
    "@njit\n",
    "def np_max(array, axis):\n",
    "    return np_apply_along_axis(np.max, axis, array)\n",
    "\n",
    "\n",
    "@njit\n",
    "def np_min(array, axis):\n",
    "    return np_apply_along_axis(np.min, axis, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "       \n",
    "    ## first, simulate some AR1 inflation with known parameters \n",
    "    ρ0,σ0 = 0.95,0.1\n",
    "    history0 = SimAR1(ρ0,\n",
    "                      σ0,\n",
    "                      200)\n",
    "    real_time0 = history0[11:-2] \n",
    "    realized0 = history0[12:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ### create a RESV instance \n",
    "\n",
    "    p0_fake = 0\n",
    "    γ_fake = 0.1\n",
    "    σs_now_fake = [0.2,0.3]\n",
    "\n",
    "    ucsv_fake = SimUCSV(γ_fake,\n",
    "                        nobs = 200,\n",
    "                        p0 = p0_fake,\n",
    "                        ) \n",
    "\n",
    "    xx_real_time,xx_p_real_time,vol_p_real_time,vol_t_real_time = ucsv_fake  \n",
    "\n",
    "    xx_realized = xx_real_time[1:-1]\n",
    "\n",
    "    xx_real_time= np.array([xx_real_time,\n",
    "                            xx_p_real_time,\n",
    "                            vol_p_real_time,\n",
    "                            vol_t_real_time]\n",
    "                          )[:,0:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sticky Expectation and Noisy Information Hybrid(SENI) + AR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = [\n",
    "    ('exp_para', float64[:]),             # parameters for expectation formation, empty for re\n",
    "    ('process_para', float64[:]),         # parameters for inflation process, 2 entries for AR1 \n",
    "    ('horizon', int64),                   # forecast horizons \n",
    "    ('real_time',float64[:]),             # real time data on inflation \n",
    "    ('history',float64[:]),               # a longer history of inflation \n",
    "    ('realized',float64[:])               # realized inflation \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     1,
     14,
     18,
     150
    ]
   },
   "outputs": [],
   "source": [
    "@jitclass(model_data)\n",
    "class SENIHybridAR:\n",
    "    def __init__(self,\n",
    "                 exp_para,\n",
    "                 process_para,\n",
    "                 real_time,\n",
    "                 history,\n",
    "                 horizon = 1):\n",
    "        self.exp_para = exp_para\n",
    "        self.process_para = process_para\n",
    "        self.horizon = horizon\n",
    "        self.real_time = real_time\n",
    "        self.history = history\n",
    "\n",
    "    def GetRealization(self,\n",
    "                       realized_series):\n",
    "        self.realized = realized_series\n",
    "        \n",
    "    def SimForecasts(self,\n",
    "                     n_sim = 500):\n",
    "        ## inputs \n",
    "        real_time = self.real_time\n",
    "        history  = self.history\n",
    "        realized = self.realized\n",
    "        n = len(real_time)\n",
    "        horizon = self.horizon \n",
    "        n_history =len(history)\n",
    "        n_burn = len(history) - n\n",
    "        horizon = self.horizon      \n",
    "\n",
    "        ## parameters \n",
    "        ρ,σ = self.process_para\n",
    "        lbd, sigma_pb,sigma_pr = self.exp_para\n",
    "                \n",
    "        #### The first NI part of the model \n",
    "        var_init = 5    ## some initial level of uncertainty, will be washed out after long simulation\n",
    "        sigma_v = np.array([[sigma_pb**2,0.0],[0.0,sigma_pr**2]]) ## variance matrix of signal noises \n",
    "        \n",
    "        ## simulate signals \n",
    "        nb_s = 2                                    ## the number of signals \n",
    "        H = np.array([[1.0],[1.0]])                 ## an multiplicative matrix summing all signals\n",
    "        \n",
    "        # randomly simulated signals \n",
    "        np.random.seed(12434)\n",
    "        signal_pb = self.history+sigma_pb*np.random.randn(n_history)   ## one series of public signals \n",
    "        signals_pb = signal_pb.repeat(n_sim).reshape((-1,n_sim)).T     ## shared by all agents\n",
    "        np.random.seed(13435)\n",
    "        signals_pr = self.history + sigma_pr*np.random.randn(n_sim*n_history).reshape((n_sim,n_history))\n",
    "                                                                 ### private signals are agent-specific \n",
    "            \n",
    "        ## SE part of the model, which governs if updating for each agent at each point of time \n",
    "        ## simulation of updating profile\n",
    "        ## simulation\n",
    "        np.random.seed(12345)\n",
    "        update_or_not_val = np.random.uniform(0,\n",
    "                                              1,\n",
    "                                              size = (n_sim,n_history))\n",
    "        update_or_not_bool = update_or_not_val>=1-lbd\n",
    "        update_or_not = update_or_not_bool.astype(np.int64)\n",
    "        most_recent_when = np.empty((n_sim,n_history),dtype = np.int64)    \n",
    "        ########################################################################\n",
    "        nowsignals_pb_to_burn = np.empty((n_sim,n_history),dtype = np.float64)\n",
    "        nowsignals_pr_to_burn = np.empty((n_sim,n_history),dtype=np.float64)\n",
    "        ######################################################################\n",
    "    \n",
    "        # look back for the most recent last update for each point of time  \n",
    "        for i in range(n_sim):\n",
    "            for j in range(n_history):\n",
    "                most_recent = j \n",
    "                for x in range(j):\n",
    "                    if update_or_not[i,j-x]==1 and most_recent<=x:\n",
    "                        most_recent = most_recent\n",
    "                    elif update_or_not[i,j-x]==1 and most_recent>x:\n",
    "                        most_recent = x\n",
    "                most_recent_when[i,j] = most_recent\n",
    "                ################################################################################\n",
    "                nowsignals_pr_to_burn[i,j] = signal_pb[j - most_recent_when[i,j]]\n",
    "                nowsignals_pr_to_burn[i,j] = signals_pr[i,j - most_recent_when[i,j]]\n",
    "                ## both above are the matrices of signals available to each agent depending on if updating\n",
    "                #####################################################################################\n",
    "                \n",
    "        \n",
    "        ## The second NI part of the model \n",
    "        ## Once sticky signals are prepared, agents filter as NI\n",
    "        \n",
    "        ## prepare matrices \n",
    "        nowcasts_to_burn = np.zeros((n_sim,n_history))  ### nowcasts matrix of which the initial simulation is to be burned \n",
    "        nowcasts_to_burn[:,0] = history[0]\n",
    "        nowvars_to_burn = np.zeros((n_sim,n_history))   ### nowcasts uncertainty matrix\n",
    "        nowvars_to_burn[:,0] = var_init\n",
    "        Vars_to_burn = np.zeros((n_sim,n_history))      ### forecasting uncertainty matrix \n",
    "        \n",
    "        ## fill the matrices for individual moments  \n",
    "        for i in range(n_sim):\n",
    "            signals_this_i = np.concatenate((nowsignals_pb_to_burn[i,:],nowsignals_pr_to_burn[i,:]),axis=0).reshape((2,-1))\n",
    "            ## the histories signals specific to i: the first row is public signals and the second is private signals \n",
    "            Pkalman = np.zeros((n_history,nb_s))\n",
    "            ## Kalman gains of this agent for respective signals \n",
    "            Pkalman[0,:] = 0  ## some initial values \n",
    "            \n",
    "            for t in range(n_history-1):\n",
    "                step1_vars_to_burn = ρ**2*nowvars_to_burn[i,t] + σ**2\n",
    "                ## prior uncertainty \n",
    "                \n",
    "                inv = np.linalg.inv(H*step1_vars_to_burn*H.T+sigma_v) \n",
    "                ## the inverse of the noisiness matrix  \n",
    "                \n",
    "                inv_sc = np.dot(np.dot(H.T,inv),H)\n",
    "                ## the total noisiness as a scalar \n",
    "                \n",
    "                var_reduc = step1_vars_to_burn*inv_sc*step1_vars_to_burn\n",
    "                ## reduction in uncertainty from the update\n",
    "                \n",
    "                nowvars_this_2d = np.array([[step1_vars_to_burn]]) - var_reduc\n",
    "                ## update equation of nowcasting uncertainty \n",
    "                \n",
    "                nowvars_to_burn[i,t+1] = nowvars_this_2d[0,0] \n",
    "                ## nowvars_this_2d is a 2-d matrix with only one entry. We take the element and set it to the matrix\n",
    "                ### this is necessary for Numba typing \n",
    "                \n",
    "                Pkalman[t+1,:] = step1_vars_to_burn*np.dot(H.T,np.linalg.inv(H*step1_vars_to_burn*H.T+sigma_v))\n",
    "                ## update Kalman gains recursively using the signal extraction ratios \n",
    "                \n",
    "                Pkalman_all = np.dot(Pkalman[t+1,:],H)[0] \n",
    "                ## the weight to the prior forecast \n",
    "                nowcasts_to_burn[i,t+1] = (1-Pkalman_all)*ρ*nowcasts_to_burn[i,t]+ np.dot(Pkalman[t+1,:],signals_this_i[:,t+1])\n",
    "                ## kalman filtering updating for nowcasting: weighted average of prior and signals \n",
    "                \n",
    "            for t in range(n_history):\n",
    "                Vars_to_burn[i,t] = ρ**(2*horizon)*nowvars_to_burn[i,t] + hstepvar(horizon,ρ,σ)\n",
    "        \n",
    "        \n",
    "        ## burn initial histories  \n",
    "        nowcasts = nowcasts_to_burn[:,n_burn:]\n",
    "        forecasts = ρ**horizon*nowcasts \n",
    "        Vars = Vars_to_burn[:,n_burn:]\n",
    "        \n",
    "        ## compute population moments\n",
    "        forecasts_mean = np_mean(forecasts,axis=0)\n",
    "        forecasts_var = np_var(forecasts,axis=0)\n",
    "        \n",
    "        FEs_mean = forecasts_mean - realized\n",
    "            \n",
    "        Vars_mean = np_mean(Vars,axis=0) ## need to change for time-variant volatility\n",
    "        \n",
    "        forecast_moments_sim = {\"FE\":FEs_mean,\n",
    "                                \"Disg\":forecasts_var,\n",
    "                                \"Var\":Vars_mean}\n",
    "        return forecast_moments_sim\n",
    "        \n",
    "    def SMM(self):\n",
    "        \n",
    "        ρ,σ = self.process_para\n",
    "        \n",
    "        #################################\n",
    "        # inflation moments \n",
    "        #################################\n",
    "\n",
    "        InfAV  = 0.0\n",
    "        InfVar = σ**2/(1-ρ**2)\n",
    "        InfATV = ρ*InfVar\n",
    "        \n",
    "        #################################\n",
    "        # expectation moments \n",
    "        #################################\n",
    "        ## simulate forecasts\n",
    "        moms_sim = self.SimForecasts()\n",
    "        \n",
    "        FEs_sim = moms_sim['FE']\n",
    "        Disgs_sim = moms_sim['Disg']\n",
    "        Vars_sim = moms_sim['Var']\n",
    "        \n",
    "        ## SMM moments     \n",
    "        FE_sim = np.mean(FEs_sim)\n",
    "        FEVar_sim = np.var(FEs_sim)\n",
    "        FEATV_sim = np.cov(np.stack( (FEs_sim[1:],FEs_sim[:-1]),axis = 0 ))[0,1]\n",
    "        Disg_sim = np.mean(Disgs_sim)\n",
    "        DisgVar_sim = np.var(Disgs_sim)\n",
    "        DisgATV_sim = np.cov(np.stack( (Disgs_sim[1:],Disgs_sim[:-1]),axis = 0))[0,1]\n",
    "        \n",
    "        Var_sim = np.mean(Vars_sim)\n",
    "        VarVar_sim = np.var(Vars_sim)\n",
    "        VarATV_sim = np.cov(np.stack( (Vars_sim[1:],Vars_sim[:-1]),axis = 0))[0,1]\n",
    "    \n",
    "        SMMMoments = {\"InfAV\":InfAV,\n",
    "                      \"InfVar\":InfVar,\n",
    "                      \"InfATV\":InfATV,\n",
    "                      \"FE\":FE_sim,\n",
    "                      \"FEVar\":FEVar_sim,\n",
    "                      \"FEATV\":FEATV_sim,\n",
    "                      \"Disg\":Disg_sim,\n",
    "                      \"DisgVar\":DisgVar_sim,\n",
    "                      \"DisgATV\":DisgATV_sim,\n",
    "                      \"Var\":Var_sim,\n",
    "                      'VarVar':VarVar_sim,\n",
    "                      'VarATV':VarATV_sim}\n",
    "        return SMMMoments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    exp_paras_fake =  np.array([0.3,0.3,0.2])\n",
    "    ## initialize the ar instance\n",
    "    seniar0 = SENIHybridAR(exp_para = exp_paras_fake,\n",
    "                           process_para = np.array([ρ0,σ0]),\n",
    "                           real_time = real_time0,\n",
    "                           history = history0,\n",
    "                           horizon = 1)\n",
    "\n",
    "    seniar0.GetRealization(realized0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Hybrid using RE data \n",
    "- This does NOT work correctly now! Hence, not used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    ## initialize an re instance \n",
    "    rear0 = RationalExpectationAR(exp_para = np.array([]),\n",
    "                                  process_para = np.array([ρ0,σ0]),\n",
    "                                  real_time = real_time0,\n",
    "                                  history = history0,\n",
    "                                  horizon = 1)\n",
    "    \n",
    "    rear0.GetRealization(realized0) \n",
    "\n",
    "\n",
    "    ## fake data moments dictionary \n",
    "    data_mom_dict_re = rear0.SMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1m- Resolution failure for literal arguments:\n\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1m- Resolution failure for literal arguments:\n\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1mNameError: name 'np_mean' is not defined\u001b[0m\u001b[0m\n\u001b[0m\u001b[1m- Resolution failure for non-literal arguments:\n\u001b[1mNone\u001b[0m\n\u001b[0m\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: BoundFunction((<class 'numba.core.types.misc.ClassInstanceType'>, 'SimForecasts') for instance.jitclass.SENIHybridAR#7fd0ea43b430<exp_para:array(float64, 1d, A),process_para:array(float64, 1d, A),horizon:int64,real_time:array(float64, 1d, A),history:array(float64, 1d, A),realized:array(float64, 1d, A)>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /var/folders/39/ks6jc__9375c2fl7h7pwq5jh0000gn/T/ipykernel_57332/716970624.py (167)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/39/ks6jc__9375c2fl7h7pwq5jh0000gn/T/ipykernel_57332/716970624.py\", line 167:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1m- Resolution failure for non-literal arguments:\n\u001b[1mNone\u001b[0m\n\u001b[0m\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: BoundFunction((<class 'numba.core.types.misc.ClassInstanceType'>, 'SMM') for instance.jitclass.SENIHybridAR#7fd0ea43b430<exp_para:array(float64, 1d, A),process_para:array(float64, 1d, A),horizon:int64,real_time:array(float64, 1d, A),history:array(float64, 1d, A),realized:array(float64, 1d, A)>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /var/folders/39/ks6jc__9375c2fl7h7pwq5jh0000gn/T/ipykernel_57332/2109707708.py (31)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/39/ks6jc__9375c2fl7h7pwq5jh0000gn/T/ipykernel_57332/2109707708.py\", line 31:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scalar\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m## invoke estimation \u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m Est \u001b[38;5;241m=\u001b[39m \u001b[43mParaEst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mObjseniar_re\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpara_guess\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNelder-Mead\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue parameters: \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mstr\u001b[39m(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m]))) \u001b[38;5;66;03m## rational expectations \u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimates: \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mstr\u001b[39m(Est))\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mParaEst\u001b[0;34m(ObjSpec, para_guess, method, bounds, options)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mParaEst\u001b[39m(ObjSpec,\n\u001b[1;32m      3\u001b[0m             para_guess,\n\u001b[1;32m      4\u001b[0m             method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNelder-Mead\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m             bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m             options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    an estimating function that minimizes OjbSpec function that gives parameter estimates\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mObjSpec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpara_guess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                         \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m         parameter \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minimize.py:611\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     constraints \u001b[38;5;241m=\u001b[39m standardize_constraints(constraints, x0, meth)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnelder-mead\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_neldermead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowell\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_powell(fun, x0, args, callback, bounds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/optimize.py:750\u001b[0m, in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m fsim \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 750\u001b[0m     fsim[k] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m ind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(fsim)\n\u001b[1;32m    753\u001b[0m fsim \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake(fsim, ind, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/optimize.py:464\u001b[0m, in \u001b[0;36m_wrap_function.<locals>.function_wrapper\u001b[0;34m(x, *wrapper_args)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction_wrapper\u001b[39m(x, \u001b[38;5;241m*\u001b[39mwrapper_args):\n\u001b[1;32m    463\u001b[0m     ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapper_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mObjseniar_re\u001b[0;34m(paras)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mObjseniar_re\u001b[39m(paras):\n\u001b[0;32m---> 13\u001b[0m     scalar \u001b[38;5;241m=\u001b[39m \u001b[43mObjGen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseniar0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mparas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_mom_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_mom_dict_re\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmoment_choice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmoments0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpectation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scalar\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numba/core/dispatcher.py:415\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    409\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip() \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    410\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis error may have been caused by the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- argument \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (i, err)\n\u001b[1;32m    412\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m i, err \u001b[38;5;129;01min\u001b[39;00m failed_args))\n\u001b[1;32m    413\u001b[0m         e\u001b[38;5;241m.\u001b[39mpatch_message(msg)\n\u001b[0;32m--> 415\u001b[0m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtyping\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numba/core/dispatcher.py:358\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numba/core/utils.py:80\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     78\u001b[0m     value \u001b[38;5;241m=\u001b[39m tp()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1m- Resolution failure for literal arguments:\n\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1m- Resolution failure for literal arguments:\n\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1mNameError: name 'np_mean' is not defined\u001b[0m\u001b[0m\n\u001b[0m\u001b[1m- Resolution failure for non-literal arguments:\n\u001b[1mNone\u001b[0m\n\u001b[0m\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: BoundFunction((<class 'numba.core.types.misc.ClassInstanceType'>, 'SimForecasts') for instance.jitclass.SENIHybridAR#7fd0ea43b430<exp_para:array(float64, 1d, A),process_para:array(float64, 1d, A),horizon:int64,real_time:array(float64, 1d, A),history:array(float64, 1d, A),realized:array(float64, 1d, A)>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /var/folders/39/ks6jc__9375c2fl7h7pwq5jh0000gn/T/ipykernel_57332/716970624.py (167)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/39/ks6jc__9375c2fl7h7pwq5jh0000gn/T/ipykernel_57332/716970624.py\", line 167:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\u001b[0m\n\u001b[0m\u001b[1m- Resolution failure for non-literal arguments:\n\u001b[1mNone\u001b[0m\n\u001b[0m\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: BoundFunction((<class 'numba.core.types.misc.ClassInstanceType'>, 'SMM') for instance.jitclass.SENIHybridAR#7fd0ea43b430<exp_para:array(float64, 1d, A),process_para:array(float64, 1d, A),horizon:int64,real_time:array(float64, 1d, A),history:array(float64, 1d, A),realized:array(float64, 1d, A)>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /var/folders/39/ks6jc__9375c2fl7h7pwq5jh0000gn/T/ipykernel_57332/2109707708.py (31)\n\u001b[0m\n\u001b[1m\nFile \"../../../../../../var/folders/39/ks6jc__9375c2fl7h7pwq5jh0000gn/T/ipykernel_57332/2109707708.py\", line 31:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ## only expectation estimation \n",
    "\n",
    "    moments0 = ['FE',\n",
    "                'FEVar',\n",
    "                'FEATV',\n",
    "                'Disg',\n",
    "                'DisgVar',\n",
    "                'Var']\n",
    "\n",
    "    def Objseniar_re(paras):\n",
    "        scalar = ObjGen(seniar0,\n",
    "                        paras = paras,\n",
    "                        data_mom_dict = data_mom_dict_re,\n",
    "                        moment_choice = moments0,\n",
    "                        how = 'expectation')\n",
    "        return scalar\n",
    "\n",
    "\n",
    "    ## invoke estimation \n",
    "    \n",
    "    Est = ParaEst(Objseniar_re,\n",
    "            para_guess = np.array([0.5,0.5,0.5]),\n",
    "            method='Nelder-Mead')\n",
    "    \n",
    "    print('True parameters: ',str(np.array([1.0,0.0,0.0]))) ## rational expectations \n",
    "    print('Estimates: ',str(Est))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Hybrid using Hybrid \n",
    "\n",
    "- This does not work correctly till now. Not used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ## get a fake data moment dictionary under a different parameter \n",
    "    exp_paras_fake = np.array([0.2,0.4,0.5])\n",
    "    seniar1 = SENIHybridAR(exp_para = exp_paras_fake,\n",
    "                         process_para = np.array([ρ0,σ0]),\n",
    "                         real_time = real_time0,\n",
    "                         history = history0,\n",
    "                         horizon = 1)\n",
    "\n",
    "    seniar1.GetRealization(realized0)\n",
    "\n",
    "    data_mom_dict_seni= seniar1.SMM()\n",
    "\n",
    "    def Objseniar_seni(paras):\n",
    "        scalor = ObjGen(seniar0,\n",
    "                        paras = paras,\n",
    "                        data_mom_dict = data_mom_dict_seni,\n",
    "                        moment_choice = moments0,\n",
    "                        how = 'expectation')\n",
    "        return scalor\n",
    "\n",
    "    ## invoke estimation \n",
    "    Est = ParaEst(Objseniar_seni,\n",
    "            para_guess = np.array([0.5,0.5,0.5]),\n",
    "            method='Nelder-Mead')\n",
    "\n",
    "\n",
    "    print('True parameters: ',str(exp_paras_fake)) ## rational expectations \n",
    "    print('Estimates: ',str(Est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0,
     4,
     15
    ]
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ## for joint estimation \n",
    "\n",
    "    moments1 = ['InfAV',\n",
    "                'InfVar',\n",
    "                'InfATV',\n",
    "                'FE',\n",
    "                'FEVar',\n",
    "                'FEATV',\n",
    "                'Disg',\n",
    "               'DisgVar',\n",
    "               'DisgATV',\n",
    "               'Var']\n",
    "\n",
    "    def Objseniar_joint(paras):\n",
    "        scalar = ObjGen(seniar0,\n",
    "                        paras = paras,\n",
    "                        data_mom_dict = data_mom_dict_seni,\n",
    "                        moment_choice = moments1,\n",
    "                        how ='joint',\n",
    "                        n_exp_paras = 3)\n",
    "        return scalar\n",
    "\n",
    "    ## invoek estimation \n",
    "    Est = ParaEst(Objseniar_joint,\n",
    "            para_guess = np.array([0.4,0.2,0.3,0.8,0.2]),\n",
    "            method='Nelder-Mead')\n",
    "    \n",
    "    print('True process parameters: ',str(np.array([ρ0,σ0])))\n",
    "    print('Estimates: ',str(Est[3:]))\n",
    "    print('True expectation parameter',str(exp_paras_fake))  \n",
    "    print('Estimates: ',str(Est[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sticky Expectation and Noisy Information Hybrid(SENI) + SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "code_folding": [
     1,
     2,
     14,
     18,
     164,
     198
    ]
   },
   "outputs": [],
   "source": [
    "@jitclass(model_sv_data)\n",
    "class SENIHybridSV:\n",
    "    def __init__(self,\n",
    "                 exp_para,\n",
    "                 process_para,\n",
    "                 real_time,\n",
    "                 history,\n",
    "                 horizon = 1):\n",
    "        self.exp_para = exp_para\n",
    "        self.process_para = process_para\n",
    "        self.horizon = horizon\n",
    "        self.real_time = real_time\n",
    "        self.history = history\n",
    "\n",
    "    def GetRealization(self,\n",
    "                       realized_series):\n",
    "        self.realized = realized_series\n",
    "        \n",
    "    def SimForecasts(self,\n",
    "                     n_sim = 500):\n",
    "        ## inputs \n",
    "        real_time = self.real_time\n",
    "        history  = self.history\n",
    "        realized = self.realized\n",
    "        n = len(real_time[0,:])\n",
    "        horizon = self.horizon\n",
    "        n_history = len(history[0,:]) # of course equal to len(history)\n",
    "        n_burn = n_history - n\n",
    "        \n",
    "        ## get the information set \n",
    "        infoset = history \n",
    "        y_now, p_now, sigmas_p_now, sigmas_t_now= infoset[0,:],infoset[1,:],infoset[2,:],infoset[3,:]\n",
    "        sigmas_now = np.concatenate((sigmas_p_now,sigmas_t_now),axis=0).reshape((2,-1))\n",
    "        \n",
    "        \n",
    "        ## process parameters\n",
    "        γ = self.process_para\n",
    "        ## exp parameters \n",
    "        lbd,sigma_pb,sigma_pr = self.exp_para\n",
    "        var_init = 1\n",
    "        \n",
    "        ## other parameters \n",
    "        sigma_v = np.array([[sigma_pb**2,0.0],[0.0,sigma_pr**2]]) ## variance matrix of signal noises         \n",
    "        ## simulate signals \n",
    "        nb_s = 2                                    ## the number of signals \n",
    "        H = np.array([[1.0],[1.0]])                 ## an multiplicative matrix summing all signals\n",
    "        \n",
    "        \n",
    "        ## The first NI part of the model \n",
    "        # randomly simulated signals \n",
    "        np.random.seed(12434)\n",
    "        ##########################################################\n",
    "        signal_pb = p_now+sigma_pb*np.random.randn(n_history)   ## one series of public signals \n",
    "        signals_pb = signal_pb.repeat(n_sim).reshape((-1,n_sim)).T     ## shared by all agents\n",
    "        np.random.seed(13435)\n",
    "        signals_pr = p_now + sigma_pr*np.random.randn(n_sim*n_history).reshape((n_sim,n_history))\n",
    "        ##################################################################################### \n",
    "            \n",
    "        ## SE part of the model, which governs if updating for each agent at each point of time \n",
    "        ## simulation of updating profile\n",
    "        ## simulation\n",
    "        np.random.seed(12345)\n",
    "        update_or_not_val = np.random.uniform(0,\n",
    "                                              1,\n",
    "                                              size = (n_sim,n_history))\n",
    "        update_or_not_bool = update_or_not_val>=1-lbd\n",
    "        update_or_not = update_or_not_bool.astype(np.int64)\n",
    "        most_recent_when = np.empty((n_sim,n_history),dtype = np.int64)    \n",
    "        ########################################################################\n",
    "        nowsignals_pb_to_burn = np.empty((n_sim,n_history),dtype = np.float64)\n",
    "        nowsignals_pr_to_burn = np.empty((n_sim,n_history),dtype=np.float64)\n",
    "        ######################################################################\n",
    "    \n",
    "        # look back for the most recent last update for each point of time  \n",
    "        for i in range(n_sim):\n",
    "            for j in range(n_history):\n",
    "                most_recent = j \n",
    "                for x in range(j):\n",
    "                    if update_or_not[i,j-x]==1 and most_recent<=x:\n",
    "                        most_recent = most_recent\n",
    "                    elif update_or_not[i,j-x]==1 and most_recent>x:\n",
    "                        most_recent = x\n",
    "                most_recent_when[i,j] = most_recent\n",
    "                ################################################################################\n",
    "                nowsignals_pr_to_burn[i,j] = signal_pb[j - most_recent_when[i,j]]\n",
    "                nowsignals_pr_to_burn[i,j] = signals_pr[i,j - most_recent_when[i,j]]\n",
    "                ## both above are the matrices of signals available to each agent depending on if updating\n",
    "                #####################################################################################\n",
    "                \n",
    "        \n",
    "        ## The second NI part of the model \n",
    "        ## Once sticky signals are prepared, agents filter as NI\n",
    "        \n",
    "        ## prepare matrices \n",
    "        nowcasts_to_burn = np.zeros((n_sim,n_history))  ### nowcasts matrix of which the initial simulation is to be burned \n",
    "        nowcasts_to_burn[:,0] = p_now[0]\n",
    "        nowvars_to_burn = np.zeros((n_sim,n_history))   ### nowcasts uncertainty matrix\n",
    "        nowvars_to_burn[:,0] = var_init\n",
    "        Vars_to_burn = np.zeros((n_sim,n_history))      ### forecasting uncertainty matrix \n",
    "        \n",
    "        \n",
    "        ## fill the matrices for individual moments        \n",
    "        for i in range(n_sim):\n",
    "            signals_this_i = np.concatenate((nowsignals_pr_to_burn[i,:],nowsignals_pr_to_burn[i,:]),axis=0).reshape((2,-1))\n",
    "            ## the histories signals specific to i: the first row is public signals and the second is private signals \n",
    "            Pkalman = np.zeros((n_history,nb_s))\n",
    "            ## Kalman gains of this agent for respective signals \n",
    "            Pkalman[0,:] = 0  ## some initial values \n",
    "            \n",
    "            for t in range(n_history-1):\n",
    "                step1var = hstepvarSV(1,\n",
    "                                      sigmas_now[:,t],\n",
    "                                      γ[0])\n",
    "                step1_vars_to_burn = nowvars_to_burn[i,t] + step1var\n",
    "                ## prior uncertainty\n",
    "                \n",
    "                inv = np.linalg.inv(H*step1_vars_to_burn*H.T+sigma_v) \n",
    "                ## the inverse of the noisiness matrix\n",
    "                \n",
    "                inv_sc = np.dot(np.dot(H.T,inv),H)\n",
    "                ## the total noisiness as a scalar \n",
    "                \n",
    "                var_reduc = step1_vars_to_burn*inv_sc*step1_vars_to_burn\n",
    "                ## reduction in uncertainty from the update\n",
    "                \n",
    "                nowvars_this_2d = np.array([[step1_vars_to_burn]]) - var_reduc\n",
    "                ## update equation of nowcasting uncertainty \n",
    "                \n",
    "                nowvars_to_burn[i,t+1] = nowvars_this_2d[0,0] \n",
    "                ## nowvars_this_2d is a 2-d matrix with only one entry. We take the element and set it to the matrix\n",
    "                ### this is necessary for Numba typing \n",
    "                \n",
    "                Pkalman[t+1,:] = step1_vars_to_burn*np.dot(H.T,np.linalg.inv(H*step1_vars_to_burn*H.T+sigma_v))\n",
    "                ## update Kalman gains recursively using the signal extraction ratios \n",
    "                \n",
    "                Pkalman_all = np.dot(Pkalman[t+1,:],H)[0] \n",
    "                ## the weight to the prior forecast \n",
    "    \n",
    "                nowcasts_to_burn[i,t+1] = (1-Pkalman_all)*nowcasts_to_burn[i,t]+ np.dot(Pkalman[t+1,:],signals_this_i[:,t+1])\n",
    "                ## kalman filtering updating for nowcasting: weighted average of prior and signals \n",
    "                \n",
    "            for t in range(n_history):\n",
    "                stephvar = hstepvarSV(horizon,\n",
    "                                      sigmas_now[:,t],\n",
    "                                      γ[0])\n",
    "                Vars_to_burn[i,t] = nowvars_to_burn[i,t] + stephvar\n",
    "                \n",
    "        nowcasts = nowcasts_to_burn[:,n_burn:]\n",
    "        forecasts = nowcasts \n",
    "        Vars = Vars_to_burn[:,n_burn:]\n",
    "\n",
    "        \n",
    "        ## compute population moments\n",
    "        forecasts_mean = np_mean(forecasts,axis=0)\n",
    "        forecasts_var = np_var(forecasts,axis=0)\n",
    "        \n",
    "        FEs_mean = forecasts_mean - realized            \n",
    "        Vars_mean = np_mean(Vars,axis=0) ## need to change for time-variant volatility\n",
    "        \n",
    "        forecast_moments_sim = {\"FE\":FEs_mean,\n",
    "                                \"Disg\":forecasts_var,\n",
    "                                \"Var\":Vars_mean}\n",
    "        return forecast_moments_sim\n",
    "              \n",
    "    def SMM(self):\n",
    "        \n",
    "        γ = self.process_para\n",
    "        \n",
    "        #################################\n",
    "        # inflation moments \n",
    "        #################################\n",
    "\n",
    "        InfAV  = np.nan\n",
    "        InfVar = np.nan\n",
    "        InfATV = np.nan\n",
    "        \n",
    "        #################################\n",
    "        # expectation moments \n",
    "        #################################\n",
    "        ## simulate forecasts\n",
    "        moms_sim = self.SimForecasts()\n",
    "        \n",
    "        FEs_sim = moms_sim['FE']\n",
    "        Disgs_sim = moms_sim['Disg']\n",
    "        Vars_sim = moms_sim['Var']\n",
    "        \n",
    "        ## SMM moments     \n",
    "        FE_sim = np.mean(FEs_sim)\n",
    "        FEVar_sim = np.var(FEs_sim)\n",
    "        FEATV_sim = np.cov(np.stack( (FEs_sim[1:],FEs_sim[:-1]),axis = 0 ))[0,1]\n",
    "        Disg_sim = np.mean(Disgs_sim)\n",
    "        DisgVar_sim = np.var(Disgs_sim)\n",
    "        DisgATV_sim = np.cov(np.stack( (Disgs_sim[1:],Disgs_sim[:-1]),axis = 0))[0,1]\n",
    "        \n",
    "        Var_sim = np.mean(Vars_sim)\n",
    "        VarVar_sim = np.var(Vars_sim)\n",
    "        VarATV_sim = np.cov(np.stack( (Vars_sim[1:],Vars_sim[:-1]),axis = 0))[0,1]\n",
    "    \n",
    "        SMMMoments = {\"InfAV\":InfAV,\n",
    "                      \"InfVar\":InfVar,\n",
    "                      \"InfATV\":InfATV,\n",
    "                      \"FE\":FE_sim,\n",
    "                      \"FEVar\":FEVar_sim,\n",
    "                      \"FEATV\":FEATV_sim,\n",
    "                      \"Disg\":Disg_sim,\n",
    "                      \"DisgVar\":DisgVar_sim,\n",
    "                      \"DisgATV\":DisgATV_sim,\n",
    "                      \"Var\":Var_sim,\n",
    "                      'VarVar':VarVar_sim,\n",
    "                      'VarATV':VarATV_sim}\n",
    "        return SMMMoments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ## initial a sv instance\n",
    "    senisv0 = SENIHybridSV(exp_para = np.array([0.5,0.23,0.32]),\n",
    "                                   process_para = np.array([0.1]),\n",
    "                                   real_time = xx_real_time,\n",
    "                                   history = xx_real_time) ## history does not matter here, \n",
    "\n",
    "\n",
    "    senisv0.GetRealization(xx_realized)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
